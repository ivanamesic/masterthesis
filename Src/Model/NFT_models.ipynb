{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import modules.preprocessing.sampling as sampling\n",
    "import modules.preprocessing.scaling as scaling\n",
    "import modules.constants as const\n",
    "\n",
    "import numpy as np\n",
    "import modules.training.LSTMmodels as LSTMmodels\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import modules.training.training as training\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import torch\n",
    "\n",
    "import modules.utils as utils\n",
    "import modules.plot_utils as plutils\n",
    "import modules.plot_constants as pltconst\n",
    "from modules.plot_constants import uzh_colors\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltconst.set_plot_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input features\n",
    "nft_predictions_dir = \"/mnt/Ivana/Results/Tezos/NFT/Predictions/\"\n",
    "nft_metrics_dir = \"/mnt/Ivana/Results/Tezos/NFT/Metrics/\"\n",
    "\n",
    "nft_dir = const.tezos_dir + \"DataDuringProcessing/NFT/Target_tokens/\"\n",
    "\n",
    "NFT_name = \"Lost control_Iskra Velitchkova\"\n",
    "\n",
    "market_df = pd.read_csv(const.input_X_dir + \"Market.csv\")\n",
    "technical_df = pd.read_csv(const.input_X_dir + \"TechnicalIndicators.csv\")\n",
    "dates = pd.read_csv(const.input_y_dir + \"Dates.csv\")\n",
    "\n",
    "dates.Date =  pd.to_datetime(dates.Date)\n",
    "end_date =  max(dates.Date)\n",
    "\n",
    "def shorten_df(df, dates, start_date, end_date):\n",
    "    if \"Date\" not in df.columns:\n",
    "        df = pd.concat([dates, df], axis = 1)\n",
    "    \n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    df = df[(df.Date >= start_date) & (df.Date <= end_date)]\n",
    "    df.drop(\"Date\", axis = 1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "data_names = [\"market\", \"TI\", \"NFT\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "WINDOW_SIZE = 10\n",
    "STEP_SIZE = 1\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "N_EPOCHS = 80\n",
    "N_HIDDEN = 256\n",
    "LR = 0.001\n",
    "\n",
    "DO_SEGMENTATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_relevant_metrics(row, targets_all, CUTOFF = 0):\n",
    "    prediction = row[4]\n",
    "    targets = targets_all[-len(prediction):]\n",
    "    \n",
    "    if CUTOFF > 0:\n",
    "        prediction = prediction[:CUTOFF]\n",
    "        targets = targets[:CUTOFF]\n",
    "        \n",
    "    row[\"mse\"] = mean_squared_error(y_true = targets, y_pred = prediction)\n",
    "    row[\"rmse\"] = mean_squared_error(y_true = targets, y_pred = prediction, squared= False)\n",
    "    row[\"mae\"] = mean_absolute_error(y_true = targets, y_pred = prediction)\n",
    "    row[\"mape\"] = mean_absolute_percentage_error(y_true = targets, y_pred = prediction)\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3797001/1490931857.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(\"Date\", axis = 1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the following configuration: n hidden 1 = 256, epochs = 80, lr = 0.001,  segmentation = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:34<00:00,  4.87s/it]\n",
      "/tmp/ipykernel_3797001/1490931857.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(\"Date\", axis = 1, inplace=True)\n",
      "100%|██████████| 7/7 [00:45<00:00,  6.44s/it]\n",
      "/tmp/ipykernel_3797001/1490931857.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(\"Date\", axis = 1, inplace=True)\n",
      "100%|██████████| 7/7 [00:43<00:00,  6.26s/it]\n",
      "/tmp/ipykernel_3797001/1490931857.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(\"Date\", axis = 1, inplace=True)\n",
      "100%|██████████| 7/7 [00:40<00:00,  5.85s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_results = []\n",
    "print(f\"Running the following configuration: n hidden 1 = {N_HIDDEN}, epochs = {N_EPOCHS}, lr = {LR},  segmentation = {DO_SEGMENTATION}\")\n",
    "\n",
    "\n",
    "for file_name in os.listdir(nft_dir):\n",
    "    if file_name.startswith(\"Strange Creatures\"): continue\n",
    "    NFT_name = file_name.replace(\".csv\", \"\")\n",
    "    nft_df = pd.read_csv(nft_dir + file_name)\n",
    "    nft_df.Date = pd.to_datetime(nft_df.Date)\n",
    "\n",
    "    start_date = min(nft_df.Date)\n",
    "\n",
    "    nft_df_short = shorten_df(nft_df, dates, start_date, end_date)\n",
    "    market_df_short = shorten_df(market_df, dates, start_date, end_date)\n",
    "    technical_df_short = shorten_df(technical_df, dates, start_date, end_date)\n",
    "\n",
    "    all_dfs = [market_df_short, technical_df_short, nft_df_short]\n",
    "    y = nft_df_short.price.values.reshape(-1,1)\n",
    "    \n",
    "    dest_file_predictions = nft_predictions_dir + f\"Predictions_{NFT_name}.npy\"\n",
    "    dest_file_metrics = nft_metrics_dir + f\"Metrics_{NFT_name}.csv\"\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in tqdm(range(1, 8)):\n",
    "        # Choose which data combinations to exclude: dont include data set combinations if they do not include either market data or TI data\n",
    "        if i % 2 == 0: continue\n",
    "\n",
    "        X_data, dict_chosen = utils.get_data_from_combination_number(i, all_dfs, data_names=data_names)\n",
    "        X_train, y_train, X_test, y_test, scaler = sampling.prepare_input_data(X_data, y, test_size=TEST_SIZE, window_size=WINDOW_SIZE, step_size=STEP_SIZE, do_segmentation=DO_SEGMENTATION)\n",
    "        train_loader = sampling.make_data_loader(X_train, y_train, batch_size=X_train.shape[0])\n",
    "\n",
    "        model = LSTMmodels.LSTMSimple(input_size=X_train.shape[2], hidden_size=N_HIDDEN, output_size=OUTPUT_DIM)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        # Train the model\n",
    "        model, _ = training.train_model(model, train_loader, n_epochs=N_EPOCHS, optimizer=optimizer, loss_fn = mse_loss)\n",
    "        \n",
    "        # Predict on the full test set and unscale the values\n",
    "        predictions, _ = training.make_prediction(model, X_test, y_test, mse_loss)\n",
    "        predictions_unsc = scaler.inverse_transform(predictions.reshape(-1,1))\n",
    "\n",
    "        all_predictions.append({**dict_chosen, **{\"prediction\": predictions_unsc.flatten()}})\n",
    "\n",
    "        # Convert predictions to numpy format and save numpy file\n",
    "        all_predictions_df = pd.DataFrame.from_dict(all_predictions)\n",
    "    \n",
    "\n",
    "    pred_all = all_predictions_df.apply(lambda x: get_all_relevant_metrics(x, y[-len(x[4]):]), axis = 1)\n",
    "    pred_all.drop(pred_all.columns[4], axis = 1, inplace=True)\n",
    "    \n",
    "    pred_all.to_csv(dest_file_metrics, index = False)\n",
    "    np.save(dest_file_predictions,all_predictions_df.values)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[7.159170774992273, 7.183108475485501, 7.20418...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.64284667017527, 5.666270547740018, 5.653182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[7.4860135397992895, 7.278619493425124, 6.7349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.32293141435874, 6.026575275142432, 5.700425...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3                                                  4\n",
       "0  1  0  0  1  [7.159170774992273, 7.183108475485501, 7.20418...\n",
       "1  3  0  1  1  [5.64284667017527, 5.666270547740018, 5.653182...\n",
       "2  5  1  0  1  [7.4860135397992895, 7.278619493425124, 6.7349...\n",
       "3  7  1  1  1  [6.32293141435874, 6.026575275142432, 5.700425..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.load(dest_file_predictions, allow_pickle=True)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Ivana/Src/Model/NFT_models.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.23.179.174/mnt/Ivana/Src/Model/NFT_models.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(nft_predictions_dir):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.23.179.174/mnt/Ivana/Src/Model/NFT_models.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(nft_predictions_dir \u001b[39m+\u001b[39m file_name, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.23.179.174/mnt/Ivana/Src/Model/NFT_models.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     y_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(nft_dir \u001b[39m+\u001b[39m file_name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mPredictions_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "for file_name in os.listdir(nft_predictions_dir):\n",
    "    predictions = np.load(nft_predictions_dir + file_name, allow_pickle=True)\n",
    "\n",
    "\n",
    "    y_df = pd.read_csv(nft_dir + file_name.replace(\"Predictions_\", \"\").replace(\".npy\", \"\") + \".csv\")\n",
    "    y_df.Date = pd.to_datetime(y_df.Date)\n",
    "    y_df = shorten_df(y_df, dates = dates, start_date=min(y_df.Date), end_date=end_date)\n",
    "    y = y_df.price.values\n",
    "\n",
    "    pred = pd.DataFrame(predictions)\n",
    "    NFT_name  = file_name.replace(\".csv\", \"\")\n",
    "\n",
    "    y_pred = pred.loc[0, 4]\n",
    "    y_tgt = y[-len(y_pred):]\n",
    "    x = y_df.Date.values[-len(y_pred):]\n",
    "    plt.figure(figsize = (14, 8))\n",
    "    plt.plot(x, y_tgt, color=\"blue\", label = \"Target\")\n",
    "    for i, row in pred.iterrows():\n",
    "        y_pred = pred.loc[i, 4]\n",
    "        indexes_included = np.where(pred.loc[i, 1:3].values == 1)[0]\n",
    "        label = \"+\".join(np.array(data_names)[indexes_included])\n",
    "        plt.plot(x, y_pred,  label=label, linestyle=\"--\")\n",
    "\n",
    "    plt.title(NFT_name)\n",
    "    plt.grid(zorder=100, lw =0.5, color = 'lightgray')\n",
    "    leg = plt.legend(frameon=True,facecolor='white', framealpha=1, loc='upper right', fontsize=12, ncol = 2)\n",
    "    frame = leg.get_frame()\n",
    "    frame.set_linewidth(0)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price in Tezos\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
